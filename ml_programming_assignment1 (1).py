# -*- coding: utf-8 -*-
"""ML Programming assignment1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IIzB7jZ91zhAMq3NnUNL_S9OOavok4w6
"""

#ML Programming assignment1.ipynb
# Import necessary libraries
import matplotlib.pyplot as plt # Matplotlib for plotting
import numpy as np # Numpy for numerical operations
import csv  # CSV module for reading CSV files

#EXPERIMENT PARAMETERS
num_inputs_nurons = 784 # Number of input neurons
num_HL = 100 # Number of neurons in the hidden layer
num_OL = 10 # Number of neurons in the output layer (
momentum = 0.9
epochs = 50  # Number of epochs for training
eta = 0.1

# Sigmoid activation function
def sigmoid_func(X):
    return 1.0/(1.0 + np.exp(-X))

# Initialize weights and biases
#constuct W1 = Wij
W1 = np.random.rand(num_HL, num_inputs_nurons)
W1 = W1 - 0.5
#print("\nW1 :\n", W1)
DW1 = np.zeros((num_HL, num_inputs_nurons))
#print("\nDW1 :\n", DW1)

#construct B1, Bias weight matrix
B1 = np.random.rand(num_HL,)
B1 = B1 - 0.5
#print("\nB1:\n", B1)
DB1 = np.zeros(num_HL)
#print("\nDB1 :\n", DB1)

#Now we have H matrix, we need O = H . W2 + B2
#constuct W2 = Wjk
W2 = np.random.rand(num_OL, num_HL)
W2 = W2 - 0.5
DW2 = np.zeros((num_OL, num_HL))
#print("\nW2 :\n", W2)
#print("\nDW2 :\n", DW2)

#construct B2, Bias weight matrix
B2 = np.random.rand(num_OL,)
B2 = B2 - 0.5
#print("\nB2:\n", B2)
DB2 = np.zeros(num_OL)
#print("\nDB2 :\n", DB2)

def train_data(X, T):
    #Forward propogation
    global W1, W2, DW1, DW2, B1, B2, DB1, DB2
    #print ("\nX: \n", X)
    #print ("\nT: \n", T)

    H = np.dot(X, W1.transpose()) + B1
    H = sigmoid_func(H)
    #print("\nH:\n", H)

    #find Output matrix ==> O = H.W2 + B2
    O = np.dot(H, W2.transpose()) + B2
    O = sigmoid_func(O)
    #print("\nO:\n", O)

    # Delta error math formula: dk = ok(1 - ok)(tk - ok), Above formula in Matrix form - Dk = O(1 - O)(T - O) where, Dk is delta matrix for all k nurons at output layer. Ok is output matrix and Tk is the input target(label).

    # find delta error at every output layer nuron
    Dk =  np.multiply(np.multiply(O, (1 - O)), (T - O))
    #print("\nDk:\n", Dk)

    #Find delta at every hidden layer nuron, formula at hidden layer nuron dj = hj(1 - hj) (dot(wjk, dk))
    Dj =  np.multiply(np.multiply(H, (1 - H)) , np.dot(W2.transpose(), Dk))
    #print("\nDj:\n", Dj)

    #We have all deta erros at all nurons, lets  update the weithts starting from W2, Update weights at W2(Wkj)
    Dk_reshape = Dk.reshape(len(Dk), 1)
    H_reshape = H.reshape(len(H), 1)

    DW2 = np.multiply(eta, np.multiply(Dk_reshape, H_reshape.transpose())) + np.multiply(momentum,  DW2)
    #print("\nDW2:\n", DW2)

    #update weights
    #print("\n W2:\n", W2)
    W2 = W2 + DW2
    #print("\n Updated W2:\n", W2)


    #update weights for bias betwwen output and hidden layer
    DB2 = np.multiply(eta, np.multiply(Dk, 1)) + np.multiply(momentum,  DB2)
    #print("\nDB2:\n", DB2)

    #update weights for bias betwwen output and hidden layer
    DB1 = np.multiply(eta, np.multiply(Dj, 1)) + np.multiply(momentum,  DB1)
    #print("\nDB1:\n", DB1)

    #Update weights between IL -> HL W1(Wij)
    Dj_reshape = Dj.reshape(len(Dj), 1)
    X_reshape = X.reshape(len(X), 1)

    #calculate delta DW1
    DW1 = np.multiply(eta, np.multiply(Dj_reshape, X_reshape.transpose())) + np.multiply(momentum,  DW1)
    #print("\nDW1:\n", DW1)

    #print("\n W1:\n", W1)
    W1 = W1 + DW1
    #print("\n Updated W1:\n", W1)


def test_data(X, T, accu_list):
    #Forward propogation
    global W1, W2, B1, B2

    H = np.dot(X, W1.transpose()) + B1
    H = sigmoid_func(H)
    #print("\nH:\n", H)

    #find Output matrix ==> O = H.W2 + B2
    O = np.dot(H, W2.transpose()) + B2
    O = sigmoid_func(O)
    #print("\nO:\n", O)

    if (O.argmax() == T.argmax()):
        accu_list.append(1)
        #print("correclty detected")
    else:
        accu_list.append(0)

def confusion_matrix_test_data(X, T, CM):
    #Forward propogation
    global W1, W2, B1, B2

    H = np.dot(X, W1.transpose()) + B1
    H = sigmoid_func(H)
    #print("\nH:\n", H)

    #find Output matrix ==> O = H.W2 + B2
    O = np.dot(H, W2.transpose()) + B2
    O = sigmoid_func(O)

    #CM
    CM[T.argmax(), O.argmax()] +=1

def get_custom_train_data(xi_input, data_set_size):
    x_temp_list = []
    cls_inserted =  [0] * num_OL
    if (data_set_size == "quarter"):
        num_each_labels = int(15000/10)
    if (data_set_size == "half"):
        num_each_labels = int(30000/10)

    print("Num Each Labels: ", num_each_labels)
    for i in range(len(xi_input)):
        for cls_num in range(num_OL):
            if (xi_input[i][0] == str(cls_num)):
                if(cls_inserted[cls_num] < num_each_labels):
                    cls_inserted[cls_num] += 1
                    x_temp_list.append(xi_input[i])

    #print("TEMP list: ", x_temp_list)
    print("Num of class labels taken : ", cls_inserted)
    return x_temp_list

#open the data
train_file = open("/content/mnist_train.csv", "r")
test_file = open("///content/mnist_test.csv", "r")
input_train_data = list(csv.reader(train_file, delimiter=","))
input_test_data = list(csv.reader(test_file, delimiter=","))

#prepare xi_input and xi_test complete matrix
# Set the data size parameter (currently empty, can be "HALF" or "QUARTER")
DATA_SIZE = " "
if (DATA_SIZE == "HALF"):
    print("\nTaking only half data set distributed equally amoung all classes\n")
    xi_i_half = get_custom_train_data(input_train_data, "half")
    xi_i = np.array(xi_i_half)
elif (DATA_SIZE == "QUARTER"):
    print("\nTaking only quarter data set distributed equally amoung all classes\n")
    xi_i_qtr = get_custom_train_data(input_train_data, "quarter")
    xi_i = np.array(xi_i_qtr)
else:
    xi_i = np.array(input_train_data)
# Extract features and labels from the training data
xi_input = xi_i[1:,]
xi_t = np.array(input_test_data)
xi_test = xi_t[1:,]

accu_train_plot_list = []
accu_test_plot_list = []


#start the epoch's
for epoch_num in range(epochs):
    print("Training starts EPOCH", epoch_num)
    for i in range(len(xi_input)):
        X = xi_input[i]
        T = np.full((num_OL,), 0.1) # Target output vector (one-hot encoded)
        T[int(X[0])] = 0.9 # Set the target value for the corresponding class to 0.9
        X = np.asfarray(X[1:],dtype="float")/255.0
        #Trainig starts
        train_data(X, T)
                # Training starts
    print("Training ends")

    print("Testing of TRAIN DATA starts")
    accu_list = []
    for i in range(len(xi_input)):
        X = xi_input[i]
        T = np.full((num_OL,), 0.1) # Target output vector (one-hot encoded)
        T[int(X[0])] = 0.9# Set the target value for the corresponding class to 0.9
        X = np.asfarray(X[1:])/255.0
        test_data(X, T, accu_list)
    accu_array = np.asfarray(accu_list)
    accuracy = np.mean(accu_array)
    accu_train_plot_list.append(accuracy * 100)
    print("TRAIN DATA ACCURACY: ", accuracy * 100)
    print("Testing of TRAIN DATA ends")

    print("Testing of TEST DATA starts")
    accu_list = []
    for i in range(len(xi_test)):
        X = xi_test[i]
        T = np.full((num_OL,), 0.1)
        T[int(X[0])] = 0.9
        X = np.asfarray(X[1:])/255.0
        #Testing starts
        test_data(X, T, accu_list)
    accu_array = np.asfarray(accu_list)
    accuracy = np.mean(accu_array)
    accu_test_plot_list.append(accuracy * 100)
    print("TEST DATA ACCURACY: ", accuracy * 100)
    print("Testing of TEST DATA ends")

        # Calculate and display confusion matrix for the last epoch


    if (epoch_num == (epochs-1)):
        print("FINDING CONFUSION MATRIX ON TEST DATA START")
        CM = np.zeros((num_OL, num_OL),  dtype=int)
        for i in range(len(xi_test)):
            X = xi_test[i] # Input features
            T = np.full((num_OL,), 0.1)  # Target output vector (one-hot encoded)
            T[int(X[0])] = 0.9
            X = np.asfarray(X[1:])/255.0  # Set the target value for the corresponding class to 0.9
            confusion_matrix_test_data(X, T, CM)# Update confusion matrix

        print("\n\nCONFUSION MATRIX ON TEST DATA: \n", CM)
        print("\nFINDING CONFUSION MATRIX ON TEST DATA END")

#plot the data on graph
plt.plot(accu_train_plot_list)
plt.plot(accu_test_plot_list)
plt.xlabel("Epochs")
plt.ylabel("Accuracy(%)")
plt.show()

train_file.close()
test_file.close()